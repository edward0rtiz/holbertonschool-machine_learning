#!/usr/bin/env python3
"""Script to train a model using mini batch"""


import tensorflow as tf
shuffle_data = __import__('2-shuffle_data').shuffle_data


def train_mini_batch(X_train, Y_train, X_valid, Y_valid,
                     batch_size=32, epochs=5, load_path="/tmp/model.ckpt",
                     save_path="/tmp/model.cpkt"):
    """
    Function to train a DNN using mini_batch gradient descent algorithm
    Args:
        X_train: numpy.ndarray of shape (m, 784)
                 contains training data
        Y_train: one-hot numpy.ndarray of shape (m, 10)
                 contains training labels
        X_valid: numpy.ndarray of shape (m, 784)
                 contains validation data
        Y_valid: one-hot numpy.ndarray of shape (m, 10)
                 contains validation labels
        batch_size: type int number of data points in a batch
        epochs: type int number of times the training should pass
                through the whole dataset
        load_path: path from which to load the model
        save_path: path to where the model should be saved after training

    Returns: path where the model was saved

    """

    with tf.Session() as sess:
        saver = tf.train.import_meta_graph(load_path + ".meta")
        saver.restore(sess, load_path)

        x = tf.get_collection("x")[0]
        y = tf.get_collection("y")[0]
        accuracy = tf.get_collection("accuracy")[0]
        loss = tf.get_collection("loss")[0]
        train_op = tf.get_collection("train_op")[0]

        m = X_train.shape[0]
        if (m % batch_size) == 0:
            num_minibatches = int(m / batch_size)
            check = 1
        else:
            num_minibatches = int(m / batch_size) + 1
            check = 0

        init = tf.global_variables_initializer()
        saver = tf.train.Saver()
        sess.run(init)
        for epoch in range(epochs + 1):
            feed_train = {x: X_train, y: Y_train}
            feed_valid = {x: X_valid, y: Y_valid}
            train_cost = sess.run(loss, feed_train)
            train_accuracy = sess.run(accuracy, feed_train)
            valid_cost = sess.run(loss, feed_valid)
            valid_accuracy = sess.run(accuracy, feed_valid)

            print("After {} epochs:".format(epoch))
            print("\tTraining Cost: {}".format(train_cost))
            print("\tTraining Accuracy: {}".format(train_accuracy))
            print("\tValidation Cost: {}".format(valid_cost))
            print("\tValidation Accuracy: {}".format(valid_accuracy))

            if epoch < epochs:
                Xs, Ys = shuffle_data(X_train, Y_train)

                for step_number in range(num_minibatches):
                    start = step_number * batch_size
                    end = (step_number + 1) * batch_size
                    if check == 0 and step_number == num_minibatches - 1:
                        x_minbatch = Xs[start::]
                        y_minbatch = Ys[start::]
                    else:
                        x_minbatch = Xs[start:end]
                        y_minbatch = Ys[start:end]

                    step_cost = sess.run(loss,
                                         feed_dict={x: x_minbatch,
                                                    y: y_minbatch})
                    step_accuracy = sess.run(accuracy,
                                             feed_dict={x: x_minbatch,
                                                        y: y_minbatch})

                    if (step_number % 100 == 0) and (step_number is not 0):
                        print("\tStep {}:".format(step_number))
                        print("\t\tCost: {}".format(step_cost))
                        print("\t\tAccuracy: {}".format(step_accuracy))
                    sess.run(train_op,
                             feed_dict={x: x_minbatch, y: y_minbatch})
        save_path = saver.save(sess, save_path)
    return save_path
